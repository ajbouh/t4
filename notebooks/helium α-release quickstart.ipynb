{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook is a five-minute tour of T4, using the `helium` Python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/miniconda3/envs/quilt-dev/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import helium as he"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T4 lets you manipulate **files** on your local machine and **objects** in the S3 bucket backing T4. Objects are just files with some additional metadata.\n",
    "\n",
    "To start off, we'll need some data. Here's a script we've built that downloads and cleans up an NOAA hurricane dataset known as HURDAT. It is pretty typical of the sorts of clean-up scripts you'd be running when performing data science:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load hurdat/build.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script generates a history of Atlantic hurricanes in a `pandas` `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>record_identifier</th>\n",
       "      <th>status_of_system</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>maximum_sustained_wind_knots</th>\n",
       "      <th>maximum_pressure</th>\n",
       "      <th>34_kt_ne</th>\n",
       "      <th>...</th>\n",
       "      <th>34_kt_sw</th>\n",
       "      <th>34_kt_nw</th>\n",
       "      <th>50_kt_ne</th>\n",
       "      <th>50_kt_se</th>\n",
       "      <th>50_kt_sw</th>\n",
       "      <th>50_kt_nw</th>\n",
       "      <th>64_kt_ne</th>\n",
       "      <th>64_kt_se</th>\n",
       "      <th>64_kt_sw</th>\n",
       "      <th>64_kt_nw</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-94.8</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-95.4</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25 12:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-96.0</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25 18:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.1</td>\n",
       "      <td>-96.5</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25 21:00:00</td>\n",
       "      <td>L</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.2</td>\n",
       "      <td>-96.8</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id     name                date record_identifier  \\\n",
       "index                                                            \n",
       "0      AL011851  UNNAMED 1851-06-25 00:00:00               NaN   \n",
       "1      AL011851  UNNAMED 1851-06-25 06:00:00               NaN   \n",
       "2      AL011851  UNNAMED 1851-06-25 12:00:00               NaN   \n",
       "3      AL011851  UNNAMED 1851-06-25 18:00:00               NaN   \n",
       "4      AL011851  UNNAMED 1851-06-25 21:00:00                 L   \n",
       "\n",
       "      status_of_system latitude longitude maximum_sustained_wind_knots  \\\n",
       "index                                                                    \n",
       "0                   HU     28.0     -94.8                           80   \n",
       "1                   HU     28.0     -95.4                           80   \n",
       "2                   HU     28.0     -96.0                           80   \n",
       "3                   HU     28.1     -96.5                           80   \n",
       "4                   HU     28.2     -96.8                           80   \n",
       "\n",
       "      maximum_pressure 34_kt_ne   ...    34_kt_sw 34_kt_nw 50_kt_ne 50_kt_se  \\\n",
       "index                             ...                                          \n",
       "0                  NaN      NaN   ...         NaN      NaN      NaN      NaN   \n",
       "1                  NaN      NaN   ...         NaN      NaN      NaN      NaN   \n",
       "2                  NaN      NaN   ...         NaN      NaN      NaN      NaN   \n",
       "3                  NaN      NaN   ...         NaN      NaN      NaN      NaN   \n",
       "4                  NaN      NaN   ...         NaN      NaN      NaN      NaN   \n",
       "\n",
       "      50_kt_sw 50_kt_nw 64_kt_ne 64_kt_se 64_kt_sw 64_kt_nw  \n",
       "index                                                        \n",
       "0          NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "1          NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "2          NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "3          NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "4          NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atlantic_storms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and write objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`helium` lets you write in-memory Python objects like this one straight to T4 using `put`. `put` also accepts a `metadata` argument, which we'll use in this example to keep track of where this data came from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "he.put(atlantic_storms, \"alpha-quilt-storage/~aleksey/hurdat/atlantic-storms-data.parquet\",\n",
    "       meta={'source': 'https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2017-050118.txt', \n",
    "             'ocean': 'atlantic'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later on you can retrieve them (along with the metadata) using `get`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlantic_storms, meta = he.get(\"alpha-quilt-storage/~aleksey/hurdat/atlantic-storms-data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2017-050118.txt',\n",
       " 'ocean': 'atlantic'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`put` and `get` uses reasonable defaults to read and write the data for you. In this example, that meant writing a `pandas` `DataFrame` into a `parquet` file.\n",
    "\n",
    "Alternatively, you can `put_file` to T4 from a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"~/Desktop/atlantic-storms.csv\"\n",
    "atlantic_storms.to_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atlantic-storms.csv\r\n"
     ]
    }
   ],
   "source": [
    "%ls ~/Desktop | grep 'atlantic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e307472d744bdfba46ccdd9afbf8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3871481), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "he.put_file(\"/Users/alex/Desktop/atlantic-storms.csv\", \"alpha-quilt-storage/~aleksey/hurdat/atlantic-storms-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version object\n",
    "\n",
    "S3, which T4 is based on, manages data objects using versions. A **version** is a record of the state of an S3 object at a particular point in time.\n",
    "\n",
    "Each version of an object is assigned a unique hash. You can retrieve that hash in T4 using the `ls` command. For example, here are the first three versions of some files in our HURDAT project (snipped here for legibility):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ETag': '\"7d9faecef6a675b04246fda5d2747a7f\"',\n",
       "  'Size': 40,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'Key': '~aleksey/hurdat/',\n",
       "  'VersionId': 'jwSyCWiv_zL5Lg.sOyN1RMMQCnGzk.0O',\n",
       "  'IsLatest': False,\n",
       "  'LastModified': datetime.datetime(2018, 10, 4, 21, 13, 14, tzinfo=tzutc()),\n",
       "  'Owner': {'DisplayName': 'kmoore',\n",
       "   'ID': '1e740c9f01d3eb40d580b51a943de9c75ba2af0c2f75e1ac7b021cd7afd1872a'}},\n",
       " {'ETag': '\"7d9faecef6a675b04246fda5d2747a7f\"',\n",
       "  'Size': 40,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'Key': '~aleksey/hurdat/',\n",
       "  'VersionId': 'HvmCd4AGwG4Og3mwGxQMfPDWiZhmtII3',\n",
       "  'IsLatest': False,\n",
       "  'LastModified': datetime.datetime(2018, 10, 4, 21, 11, 41, tzinfo=tzutc()),\n",
       "  'Owner': {'DisplayName': 'kmoore',\n",
       "   'ID': '1e740c9f01d3eb40d580b51a943de9c75ba2af0c2f75e1ac7b021cd7afd1872a'}},\n",
       " {'ETag': '\"7d9faecef6a675b04246fda5d2747a7f\"',\n",
       "  'Size': 40,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'Key': '~aleksey/hurdat/',\n",
       "  'VersionId': 'iUxtMYQh.Z3mInIaitovWpdEP3XY9DKb',\n",
       "  'IsLatest': False,\n",
       "  'LastModified': datetime.datetime(2018, 10, 4, 21, 9, 53, tzinfo=tzutc()),\n",
       "  'Owner': {'DisplayName': 'kmoore',\n",
       "   'ID': '1e740c9f01d3eb40d580b51a943de9c75ba2af0c2f75e1ac7b021cd7afd1872a'}}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he.ls(\"alpha-quilt-storage/~aleksey/hurdat\")[1][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the future, we will have other ways of accessing version information more directly.\n",
    "\n",
    "You can download an object as of a specific `VersionId` using the optional `version` keyword argument in `get` or `get_file`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, meta = he.get(\"alpha-quilt-storage/~aleksey/hurdat/atlantic-storms.parquet\", \n",
    "                    version=\"mP4USSZF2mJSaKNvr7EjUldDQm3Sqb_b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you need to provide the full version hash for this to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snapshot your projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- In the future this section should treat versions, not snapshots. -->\n",
    "\n",
    "Snapshots are the core abstraction in T4. A **snapshot** is a static view of a set of files in T4.\n",
    "\n",
    "Creating a snapshot is easy. Just call `snapshot` on an S3 key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2d24be29ebb0c9cf785bcb8dfd390f6821b4ce57fb205790a2abd1567cf9c79b'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he.snapshot(\"alpha-quilt-storage/~aleksey/hurdat/atlantic-storms-data.parquet\",\n",
    "            message=\"First snap.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can list snapshots of an S3 key using `list_snapshots`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>~aleksey/atlantic-storms-data.parquet</th>\n",
       "      <td>de63c7c1bddb4426bb4bced7aedff30d4c9df3dc406e4b...</td>\n",
       "      <td>2018-10-08 21:38:10+00:00</td>\n",
       "      <td>First snap.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>435d7b954fe6dbd35cf51b311971fc49643d24af9f6f69...</td>\n",
       "      <td>2018-10-08 21:21:01+00:00</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[{'hash': 'de63c7c1bddb4426bb4bced7aedff30d4c9df3dc406e4bb9d885699c90894b37',\n",
       "  'path': '~aleksey/atlantic-storms-data.parquet',\n",
       "  'message': 'First snap.',\n",
       "  'timestamp': datetime.datetime(2018, 10, 8, 21, 38, 10, tzinfo=tzutc())},\n",
       " {'hash': '435d7b954fe6dbd35cf51b311971fc49643d24af9f6f698544f87d7e24ebe83c',\n",
       "  'path': '',\n",
       "  'message': 'foo',\n",
       "  'timestamp': datetime.datetime(2018, 10, 8, 21, 21, 1, tzinfo=tzutc())}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he.list_snapshots(\"alpha-quilt-storage/~aleksey/atlantic-storms-data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snapshots can be used to version anything with an S3 key, but are at their most useful when versioning **data packages**: groups of files which together represent the data component to a specific project you are working on.\n",
    "\n",
    "You can think of a data project as having three components: code, environment, and data. Versioning code is obvious: just use `git`. Similarly, sophisticated tools exist for versioning environments: `conda` and Docker, for example.\n",
    "\n",
    "But what about your data? Data can balloon to many terabytes in size, becoming too large for `git` or Docker to manage. At the same time, in data science, small changes in data can often have disproportionate impact in your analysis and throw off your models. In a [seminal paper](https://ai.google/research/pubs/pub43146) on data systems, Google refered to this as the CACE principle: \"Changing Anything Changes Everything\". \n",
    "\n",
    "Clearly, data needs its own native versioning tool. T4 snapshots provide just that!\n",
    "\n",
    "To demonstrate, let's start by cloning a simple project using our storms data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ~/Desktop; git clone https://github.com/ResidentMario/hurdat-example-repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project contains an `environment.yml` file defining our code environment, a `notebooks` folder containing some Jupyter notebooks, and a `data` folder containing inputs and outputs.\n",
    "\n",
    "Our objective: smartly manage our `data`. With T4 snapshots, this is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: replace this path with one that works on your local machine.\n",
    "he.put_file(\"/Users/alex/Desktop/hurdat-example-repo/data/\", \n",
    "            \"alpha-quilt-storage/aleksey/hurdat-example-repo/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he.snapshot(\"alpha-quilt-storage/aleksey/hurdat-example-repo/data/\", message=\"Snap.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he.list_snapshots(\"alpha-quilt-storage/aleksey/hurdat-example-repo/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now whenever we want to grab a file from a particular snapshot of this particular data project, we need only pass its hash to the `snapshot` parameter of `get_file`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: replace this path with one that works on your local machine.\n",
    "he.get_file(\"alpha-quilt-storage/aleksey/hurdat-example-repo/data/atlantic.csv\", \n",
    "            \"/Users/alex/Desktop/hurdat-example-repo/data/atlantic.csv\",\n",
    "            snapshot=\"cb06134062b8b8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check this hash into your `README.md` and enjoy your newfound project reproducibility!\n",
    "\n",
    "In summary, every data science product&mdash;be it an analysis, a model, or exposition&mdash;relies on a new collection of data file **versions**, which a data science can logically organize into one (or more) **snapshots**. These snapshots are **immutable**, and, in conjunction with version control on the project code and the project environment, enable reproducible, distributable data science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addendum&mdash;clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "!rm -rf ~/Desktop/hurdat-example-repo\n",
    "!rm ~/Desktop/atlantic-storms.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
